% !TeX spellcheck = en_GB
\documentclass[11pt]{article}
\usepackage{graphicx}
\usepackage{listings}
\title{Machine Learning Project\\Task 2}
\author{Duy Nguyen Dinh \\ dinh@rhrk.uni-kl.de\and
	Minh Duc Duong\\ duong@rhrk.uni-kl.de\and
    ---\\ ---}
\date{\today}
\begin{document}

\maketitle

\section{Data Pre-processing}

\subsection{Extract vintage from "title" column}
As the task sheet requires, we need to extract the vintage from the title column. First it is necessary to identify how would vintage appears in the title. Because they indicate a specific year, they appear mostly as a concatenation of 4 digits. The process can be done by searching for numbers using regular expression ([0-9][0-9][0-9][0-9]) in each entry of title column. This is however not enough for the exaction as there can be the case, where the 4 digits do not make any sense of year (for example: 1000 or 9000 as these should not be a reasonable years for vintage). Thus, we add some constraints with the expectation of getting more meaningful numbers for the vintage. The extracted number first should be in between 1800 and 2022 because it makes more sense that all wines were made in this year range. Also there are time when we could extracted 2 or more years in the same title entry. Here we focus on the exception with 2 different numbers. The entry 2262 in the data has 2 different years (1637 and 2002). Our implementation is to extract the maximum number as vintage, which suits this entry well because 1637 represents the establish year of the facility and 2002 is the actual wine year.

It is important to keep in mind that the extraction may not absolute accurate because the idea for the extraction of vintage comes through the observation of the data frame. For the better result, data should be consistent with a recognizable pattern.

\subsection{Histogram}
Plotting is one way to get an overview of the values of each column. There will be two types of plotting depend on the value type of columns. For numeric types (Integer or Float), we plot histograms which show the range and the distribution of values. For string type, we plot the counts of each unique values.

Because there can be too many unique values to plot, we decided to plot the counts of top 20 unique values for string columns. We also exclude description and title columns from the plot result with the assumption that each entry of these columns are unique and this makes plotting for these columns serves no purpose.

Country

\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/1c_histogram_of_country.png}

Designation

\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/1c_histogram_of_designation.png}

Points (bin=10)

\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/1c_histogram_of_points.png}

Price (bin=80)

\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/1c_histogram_of_price.png}

Province

\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/1c_histogram_of_province.png}

Region\_1

\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/1c_histogram_of_region_1.png}

Region\_2

\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/1c_histogram_of_region_2.png}

Taster\_name

\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/1c_histogram_of_taster_name.png}

Taster\_twitter\_handle

\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/1c_histogram_of_taster_twitter_handle.png}

Variety

\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/1c_histogram_of_variety.png}

Winery

\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/1c_histogram_of_winery.png}

Vintage (bin=10)

\includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/1c_histogram_of_vintage.png}

We also retrieve the number of null entries for each column:

\begin{itemize}
    \item country                     63
    \item description                  0
    \item designation              37465
    \item points                       0
    \item price                     8996
    \item province                    63
    \item region\_1                 21247
    \item region\_2                 79460
    \item taster\_name              26244
    \item taster\_twitter\_handle    31213
    \item title                        0
    \item variety                      1
    \item winery                       0
    \item vintage                   4611
\end{itemize}

\subsection{Statistics}



\subsection{Data Transformation}

In this task, we transform each column individually and force each output to be a 2d matrix. We set the threshold of missing data on each row to 2. It means for example, a row that misses the country and province will be removed from the dataset.

Data from the columns will be classified into 3 types: numerical, categorical and text data.

Numerical data includes \textbf{price}, \textbf{vintage}, \textbf{points}. For this data type, we reshape it from an 1d-array to a (N,1) matrix. Missing data will be fulfilled with the mean of the correspondent column. We will observe their standard deviation to assess the impact on the related weight of the model.

Only the \textbf{description} column includes text data. First, texts will be tokenized and stop words and other with frequency less than 2 will be filtered out. Then a dictionary is created by the remaining words. We use Word2Vec model from the library Gensim to vectorize the description string. Next, the model will be trained for 20 epochs. Finally, the model transform each description into a vector with size 50.

The rest are categorical data. We can see also a set of hierachical type: {country, province, region_1, region_2}. There are plenty of encoding technics for that type of data. In this project we use mainly three methods: Sum encoding, Binary encoding, Target encoding. Sum encoding will be applied to the columns with a small set of categories like \textbf{taste_name}, \textbf{province}. It is an efficient method which represent the nature of categorical variable's encoding, but memory and runtime are the trade-off. In Sum encoding, missing data will be set to a vector of minus one. For columns that have a huge amount of categories and a small impact on the target column, we use binary encoding to reduce the features. The involved columns include \textbf{region_1} (1229 categories to 11 binary features), \textbf{winery} (16757 to 15), \textbf{designation} (37979 to 16), \textbf{variety} (707 to 10). We apply target encoding on \textbf{country}. Target encoding would lead to overfitting, therefore we use the version with additive smoothing. In this encoding, missing data will be set to the general mean.

We realized that \textbf{taster_twitter_handle} data is identical with taster_name, when it exists. So, we decide to transform it into a boolean feature, expresses that whether the taster has a taster account. the tranformed data has only one variable, the feature correlation between \textbf{taster_name} and \textbf{taster_twitter_handle} is eliminated.

\textbf{title} is just the concatination of designation, vintage, variety, winery. Therefore, we ignore this column.

\subsection{f}

When new type of wine is added, we still need some constraints to check if this is actual new type. For example, with a specific implementation, "US", "USA" and "America" in column country are totally different. This means we need a way to standardize the values for each column and different input values with the same context should be grouped together. When we reach a specific number of newly added row, the description column should be pre-processed again, as the description column relates to other columns best and use training algorithm to vectorize values.
\section{Ridge Regression}

\subsection{Forward step selection}
We want to find the most impact features in the data and forward step selection is one of the options. We first start with an empty model with no fitted data, then we find the best feature to add to the model. This can be done base on the mean squared errors when we add each available feature to the model. We keep adding features into the model until we reach a certain number k.

As for the result of the given wine data:
\begin{itemize}
    \item k=0: Feature: description with the mse of 596.297918013402
    \item k=1: Feature: country with the mse of 5.609319585427947
    \item k=3: Feature: province with the mse of 4.878210024539221
    \item k=4: Feature: taster\_name with the mse of 4.75865561866921
\end{itemize}

The most significant features are the one with many unique values across the data (description, country) because the column with more unique values will contain better relations with other column. On the other hand, if most row cluster into a certain value or range of values (price/points/vintage), this makes prediction harder because the values do not hold any meaning for a good estimation (as completely different wine can have the same points)

% Print references
\end{document}
